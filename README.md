# Kaggle-learning
Machine Learning Explainability
Permutation Importance——可以将data的某一column进行打乱，然后测试其对准确性的影响，从而选择data的有效特征，主要应用的模块为eli5 PermutationImportance
Partial Plots——实际上也是判断数据对于结果的影响，数据波动越大越长则认为对结果影响越大，2D图基本算是一个相关图，两个变量的相关性....官方解释
这些旨在解决我在听人们讨论部分依赖图时听到的一些常见误解。
例如，我听说有人说，如果局部绘图是平坦的，则变量一定无关紧要……否则您可以放心地将其删除。
但是您已经证明，即使创建平坦的局部图，创建非常重要的解决方案也是错误的。
我听说有人声称波动（某些东西不是单调的）可能反映了模型中的假设。 尽管在某些情况下这可能是可行的，但通过显示原始数据的来源已证明并非如此。
更普遍地说，我认为能够在这些洞察图中看到的内容与原始数据中的哪种类型的原因之间来回切换非常重要。 因此，我希望您能练习此技能，并减少我上面描述的错误类型。
SHAP Values——
